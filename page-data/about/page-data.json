{"componentChunkName":"component---src-templates-post-tsx","path":"/about/","result":{"data":{"logo":{"childImageSharp":{"gatsbyImageData":{"layout":"fixed","backgroundColor":"#080808","images":{"fallback":{"src":"/static/2b5eaa0de166a8b5faebad4955c2200c/6f314/ghost-logo.png","srcSet":"/static/2b5eaa0de166a8b5faebad4955c2200c/6f314/ghost-logo.png 464w","sizes":"464px"},"sources":[{"srcSet":"/static/2b5eaa0de166a8b5faebad4955c2200c/8b1cb/ghost-logo.webp 464w","type":"image/webp","sizes":"464px"}]},"width":464,"height":149}}},"markdownRemark":{"html":"<h1>The challenge</h1>\n<p>Computer simulation is often refered to as the <em>third methodology</em>, complementing theory and experimentation for scientific and engineering research. More efficient aircraft designs, potental vaccines against disseases, increased understanding of the cosmos, more accurate weather modelling, and greater understanding of the fundamental forces underlying matter are just a few of the very many impacts that simulation has delivered, in-fact the vast majority of scientific and engineering developments of the past 20 years have, to some extent, involved simulation.</p>\n<img src=\"/img/application_front_page.png\" width=\"200\" align=\"right\">\n<p>Given the importance of computer simulation it is no wonder that users are constantly demanding the ability to undertake more detailed runs at reduced time to solution. This raises a significant technological challenge, where both hardware and software struggle to keep up with such ambitions. Whilst there have been very significant improvements at the hardware level arguably many challenges have also been pushed over to the software side. A prime example of this was the leveling off of clock frequency increases, where the industry responded by significantly increasing the amount of parallelism to compensate and contine the growth in performance. We are now in a situation even with current generation supercomputers were the programming challenge to fully exploit an HPC machine is significant, with programmers needing to consider multiple levels of parallelism (inter-node, intra-node but inter-socket, inter-socket, instruction level) and the interoperability of heterogeneous architectures such as CPUs and GPUs.</p>\n<h2>Exascale computing on the horizon</h2>\n<p>There is a great push in the community to develop exascale supercomputers, which are capable of performing over a Quintillion floating point calculations per second. Hardware has developed significantly towards this goal but in a way that presents more complexity to the end-user, for instance via high degrees of hardware heterogeneity, extremely large amounts of parallelism, deeper memory hierarchies, and novel hardware architectures. Whilst these facets can achieve such exascale raw performance, they make the programming of such machines far more complex using current approaches to writing HPC codes. This means that there is a danger that, in the coming decade, we will have extremely powerful supercomputing hardware but on a small number of applications that can fully exploit this who are able to invest the time of the few highly skilled experts in programming them.</p>\n<h2>Domain Specific Languages (DSLs) to the rescue?</h2>\n<p>It might be surprising that, by far, the most popular language that HPC codes are written in is Fortran. Whilst more modern languages, such as C++ and Python are slowly gaining more traction, the choice of Fortran due to its convenient language features for writing scientific codes and mature compiler support certainly made a lot of sense traditionally. However Fortran is a general purpose language where the programmer must specify the <em>how</em> as well as the <em>what</em> of their parallel computation. By raising the abstraction level to suit the specific application domain in question, then programmers can not only much more conveniently encode their applications but also the compiler has a rich amount of information about which it can use to make tricky, low level choices around how best to run the code in parallel.</p>\n<p>Domain Specific Languages (DSLs) have grown in popularity in recent years and enable exactly this, raising the abstraction level to suiting the specific application domain in question. It has been found that these result in significant increases in programmer productivity, performance, and portability across architectures. Put simply, it is the strong belief of many in the HPC community that DSLs will enable domain, rather then HPC, experts to program and effectively exploit future exascale machines. However, the big <strong>challenge is that DSLs are typically implemented in isolation fashion with their software stacks siloed and sharing little code or infrastructure between them</strong>. This means that whilst a specific DSL might suit an application area, it’s maturity, long term support, ability to efficiently exploit current and future technology might be highly questionable. Furthermore, the development of DSLs and underlying compilation support can be time consuming, with many failing to reach wide spread adoption.</p>\n<h1>Our solution - an ecosystem for DSL development</h1>\n<p>To address the challenge of isolate DSL software stacks which can suffer from long development times, immature software stacks, uncertain long term futures, and risky buy in from users we are developing a common ecosystem. This is illustrated below, where the <em>special sauce</em> enabling such a common infrastructure is Multi Level Intermediate Representation (MLIR). MLIR is a technology that has developed over the past couple of years that provides significant flexibility when representing programming languages, with the ability to fairly easily develop new MLIR dialects and build atop existing ones. Many MLIR dialects already exist and furthermore new dialects can be easily developed to support the expressiveness required by a wide range of DSLs for running on large-scale HPC machines.</p>\n<p><img src=\"/img/overview.png\" alt=\"Overview Image\"></p>\n<p>There are many advantages to this approach, firstly the ability to benefit from a wealth of existing MLIR/LLVM tooling that already exists and successfully targets the wide range of hardware commonly found in HPC machines. This means that there is then significant reuse of infrastructure between DSLs, with improvements to specific parts of the ecosystem then often benefitting other DSLs. Furthermore it enables longevity of the DSL, as whilst the actual DSL abstraction itself might not be further developed, the underlying MLIR/LLVM compilation tools are very actively developed and maintained by a large and vibrant community. As such users can have reasonable confidence that their code will be able to run efficiently on a large number of future architectures.</p>\n<p>Such a unified ecosystem also benefits the DSL designer as they only need to implement a front-end for their language, generating the appropriate MLIR which can then benefit from the rest of the compilation stack. Many DSLs are currently encoded within Python, and as such in this project to aid the integration of such abstractions into MLIR we are developing a Python toolbox which will lower the barrier even further for DSL development. Moreover, we believe this also promotes integration between DSLs, where building upon MLIR will enable more easily sharing of features and as such open up specific DSLs to new communities.</p>\n<p>Performance portability is a key aim of this project, and we are targetting a variety of hardware including Intel, AMD, and ARM CPUs, Nvidia and AMD GPUs, Xilinx and Intel FPGAs, and the Cerebras CS-1. The hypothesis is that through existing LLVM support for these architectures and the rich dialects of MLIR then the user’s application code written in their DSL of choice can remain largely unchanged between architectures, with the underlying compilation stack being able to efficiently target the technology.</p>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"The challenge"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Computer simulation is often refered to as the "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"third methodology"}]},{"type":"text","value":", complementing theory and experimentation for scientific and engineering research. More efficient aircraft designs, potental vaccines against disseases, increased understanding of the cosmos, more accurate weather modelling, and greater understanding of the fundamental forces underlying matter are just a few of the very many impacts that simulation has delivered, in-fact the vast majority of scientific and engineering developments of the past 20 years have, to some extent, involved simulation."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"/img/application_front_page.png","width":200,"align":"right"},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Given the importance of computer simulation it is no wonder that users are constantly demanding the ability to undertake more detailed runs at reduced time to solution. This raises a significant technological challenge, where both hardware and software struggle to keep up with such ambitions. Whilst there have been very significant improvements at the hardware level arguably many challenges have also been pushed over to the software side. A prime example of this was the leveling off of clock frequency increases, where the industry responded by significantly increasing the amount of parallelism to compensate and contine the growth in performance. We are now in a situation even with current generation supercomputers were the programming challenge to fully exploit an HPC machine is significant, with programmers needing to consider multiple levels of parallelism (inter-node, intra-node but inter-socket, inter-socket, instruction level) and the interoperability of heterogeneous architectures such as CPUs and GPUs."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Exascale computing on the horizon"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"There is a great push in the community to develop exascale supercomputers, which are capable of performing over a Quintillion floating point calculations per second. Hardware has developed significantly towards this goal but in a way that presents more complexity to the end-user, for instance via high degrees of hardware heterogeneity, extremely large amounts of parallelism, deeper memory hierarchies, and novel hardware architectures. Whilst these facets can achieve such exascale raw performance, they make the programming of such machines far more complex using current approaches to writing HPC codes. This means that there is a danger that, in the coming decade, we will have extremely powerful supercomputing hardware but on a small number of applications that can fully exploit this who are able to invest the time of the few highly skilled experts in programming them."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Domain Specific Languages (DSLs) to the rescue?"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"It might be surprising that, by far, the most popular language that HPC codes are written in is Fortran. Whilst more modern languages, such as C++ and Python are slowly gaining more traction, the choice of Fortran due to its convenient language features for writing scientific codes and mature compiler support certainly made a lot of sense traditionally. However Fortran is a general purpose language where the programmer must specify the "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"how"}]},{"type":"text","value":" as well as the "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"what"}]},{"type":"text","value":" of their parallel computation. By raising the abstraction level to suit the specific application domain in question, then programmers can not only much more conveniently encode their applications but also the compiler has a rich amount of information about which it can use to make tricky, low level choices around how best to run the code in parallel."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Domain Specific Languages (DSLs) have grown in popularity in recent years and enable exactly this, raising the abstraction level to suiting the specific application domain in question. It has been found that these result in significant increases in programmer productivity, performance, and portability across architectures. Put simply, it is the strong belief of many in the HPC community that DSLs will enable domain, rather then HPC, experts to program and effectively exploit future exascale machines. However, the big "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"challenge is that DSLs are typically implemented in isolation fashion with their software stacks siloed and sharing little code or infrastructure between them"}]},{"type":"text","value":". This means that whilst a specific DSL might suit an application area, it’s maturity, long term support, ability to efficiently exploit current and future technology might be highly questionable. Furthermore, the development of DSLs and underlying compilation support can be time consuming, with many failing to reach wide spread adoption."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Our solution - an ecosystem for DSL development"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"To address the challenge of isolate DSL software stacks which can suffer from long development times, immature software stacks, uncertain long term futures, and risky buy in from users we are developing a common ecosystem. This is illustrated below, where the "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"special sauce"}]},{"type":"text","value":" enabling such a common infrastructure is Multi Level Intermediate Representation (MLIR). MLIR is a technology that has developed over the past couple of years that provides significant flexibility when representing programming languages, with the ability to fairly easily develop new MLIR dialects and build atop existing ones. Many MLIR dialects already exist and furthermore new dialects can be easily developed to support the expressiveness required by a wide range of DSLs for running on large-scale HPC machines."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"/img/overview.png","alt":"Overview Image"},"children":[]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"There are many advantages to this approach, firstly the ability to benefit from a wealth of existing MLIR/LLVM tooling that already exists and successfully targets the wide range of hardware commonly found in HPC machines. This means that there is then significant reuse of infrastructure between DSLs, with improvements to specific parts of the ecosystem then often benefitting other DSLs. Furthermore it enables longevity of the DSL, as whilst the actual DSL abstraction itself might not be further developed, the underlying MLIR/LLVM compilation tools are very actively developed and maintained by a large and vibrant community. As such users can have reasonable confidence that their code will be able to run efficiently on a large number of future architectures."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Such a unified ecosystem also benefits the DSL designer as they only need to implement a front-end for their language, generating the appropriate MLIR which can then benefit from the rest of the compilation stack. Many DSLs are currently encoded within Python, and as such in this project to aid the integration of such abstractions into MLIR we are developing a Python toolbox which will lower the barrier even further for DSL development. Moreover, we believe this also promotes integration between DSLs, where building upon MLIR will enable more easily sharing of features and as such open up specific DSLs to new communities."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Performance portability is a key aim of this project, and we are targetting a variety of hardware including Intel, AMD, and ARM CPUs, Nvidia and AMD GPUs, Xilinx and Intel FPGAs, and the Cerebras CS-1. The hypothesis is that through existing LLVM support for these architectures and the rich dialects of MLIR then the user’s application code written in their DSL of choice can remain largely unchanged between architectures, with the underlying compilation stack being able to efficiently target the technology."}]}],"data":{"quirksMode":false}},"excerpt":"The challenge Computer simulation is often refered to as the third methodology, complementing theory and experimentation for scientific and…","fields":{"readingTime":{"text":"6 min read"}},"frontmatter":{"title":"About xDSL","userDate":"12 December 1922","date":"1922-12-12T10:00:00.000Z","tags":["about"],"excerpt":"We are developing a common compilation ecosystem for DSLs, find out more here","image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/0181abd49c61d1d68f3b9b982d344232/a135c/overview.png","srcSet":"/static/0181abd49c61d1d68f3b9b982d344232/a135c/overview.png 610w","sizes":"100vw"},"sources":[{"srcSet":"/static/0181abd49c61d1d68f3b9b982d344232/5f0fd/overview.webp 610w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.7540983606557378}}},"author":[{"id":"Another Author","bio":"This is another test author with a profile background image","avatar":{"children":[{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/a8b52/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/f31ef/ghost.png 40w,\n/static/7ffe238930a689e103d70f234bb00199/1f8a1/ghost.png 80w,\n/static/7ffe238930a689e103d70f234bb00199/a8b52/ghost.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/e73fe/ghost.webp 40w,\n/static/7ffe238930a689e103d70f234bb00199/61ca6/ghost.webp 80w,\n/static/7ffe238930a689e103d70f234bb00199/507b0/ghost.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}]}}]}},"relatedPosts":{"totalCount":1,"edges":[{"node":{"id":"dc2f58d4-9e8d-55f9-b809-1797d18f4813","excerpt":"The challenge Computer simulation is often refered to as the third methodology, complementing theory and experimentation for scientific and…","frontmatter":{"title":"About xDSL","date":"1922-12-12T10:00:00.000Z"},"fields":{"readingTime":{"text":"6 min read"},"slug":"/about/"}}}]}},"pageContext":{"slug":"/about/","prev":null,"next":{"excerpt":"BoF at SC21 Tuesday 16th November 2021 12:15pm - 1:15pm CST Domain Specific Languages (DSLs) are a powerful way of providing programmer…","frontmatter":{"title":"BoF at SC21","tags":["news","frontpage"],"date":"1922-12-12T10:00:00.000Z","draft":false,"excerpt":"We are running a BoF at SC21 about a common DSL ecosystem","image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAA7DAAAOwwHHb6hkAAABtElEQVQY002QzW+TYACH+V80pq1tCXRlhdbBaPnm5YWXrzIK5aUw6GR1qTt00YMmejB68rKbZw8eNdXsbuLJf8nUxcTkyXP7JU9+xDy9QtFTf7FBUeMvNjHehukzL25gUAOvRl6F/NpwKxlgycwUmGtwpVgYBuufv34Tin7mzSsvLA2YmXYmyiF0V0FY9Gl5cArKIEw02Bvpi7TBxZUbnjt+4YZVh5zm9Q2hmIkOl6adATtTQaKCxHBy6GDNxonqvLpeby9LFcy/fd3f/bjDxfb29tN+/z2Iqhg/Jzje4aVgcuoK/8zPAl70R7wzY/V8lZ2baHKs716+ff/hY7O5efP6XdPsmImFqx3xsMP3aKVLyy1y+j9tcvqoP6NYvUXJjym5RYoUq6gmApwUi8aQFIqLF0QYr1UzkbRYt5bILy2UI7+ELvajtRdWflRH8YWFcJxeGnCZZhtFPxsweqcvHsbAzgy4vH/LhJnjrQQ5HHIWyztjweUExJ44zNgaPbGHHGDG8IgDfUZ/0D45ZCsghW5uewUKSsVYAAcPWKNDSV36UHuAlrt/6Q2Ue5NDrU1Kn7/s/wDOD5qwZZ6OZQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/94bf36549285224b5b319be7bca1c8dd/b78a6/xdsl_bof.png","srcSet":"/static/94bf36549285224b5b319be7bca1c8dd/b78a6/xdsl_bof.png 469w","sizes":"100vw"},"sources":[{"srcSet":"/static/94bf36549285224b5b319be7bca1c8dd/d0b64/xdsl_bof.webp 469w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.3837953091684435}}},"author":[{"id":"Another Author","bio":"This is another test author with a profile background image","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAAsTAAALEwEAmpwYAAABFUlEQVQ4y2MQVdQiGzEMJ80iCppwBOcSpRlZHZop+DSLKWnzS6v0Tpl5/da9E2cuXL1xZ/6SlXxSyvOXrlq8cp2ArBpBzaqNnX1HT57Zvmf/4ROnJk6fwyutMnHG3GlzFgri1wxBAjKq/NIqMKQqoqAJESHK2T2Tpl+9fuvE6XOnzl44dfbCidPnLl+7MWPeImF5DUKaZVQbO/uPnji7c++h3QeO7D5wZOfeQ4ePn+6dPJOAZgxnq4IR1AtEObt74vQr126du3jVLSDc3Mnr9LlLl6/enD53kRBhZ0urNndNOH7m3KFjJ519Q0wd3PcfOX7s9Ln+abOIcraQnLqgnJqgnJqwvIawgiaELSinPsxzFT00AwBuRuAIP+7NSQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"2 min read"},"layout":"","slug":"/bof/"}},"primaryTag":"about"}},"staticQueryHashes":["3170763342"]}